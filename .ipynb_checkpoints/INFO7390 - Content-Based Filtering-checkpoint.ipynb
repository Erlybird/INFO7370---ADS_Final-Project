{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d404a281",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9fbe25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56108bd",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2963701",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv('./dataset/dice_com-job_us_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ab8aef",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab5050fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(arr1,arr2):\n",
    "    ans=1- spatial.distance.cosine(arr1,arr2)\n",
    "    if(np.isnan(ans)):\n",
    "        return 0\n",
    "    else:\n",
    "        return ans\n",
    "class job_postings:    \n",
    "    def __init__(self,link):\n",
    "        self.df2=pd.read_csv(link)\n",
    "        self.training_range=int(len(self.df2.loc[:,'uniq_id']))\n",
    "    def match_profile(self,input_path,user_id,alpha,beta,flag=0):\n",
    "        #Match a given user_id with all jobs in the database\n",
    "        \n",
    "        #Check if user id exists\n",
    "        df=pd.read_csv(input_path+\"domain_user_profile.csv\",index_col='Respondent')\n",
    "        #print(df.columns)\n",
    "        matches=dict()\n",
    "        if(flag==0):\n",
    "            if(user_id in df.index):\n",
    "                userdomain=df.loc[user_id,:]\n",
    "                #print(userdomain)\n",
    "                #If it does, retrieve the user profile from input_path\n",
    "                df=pd.read_csv(input_path+\"languages_profile_user.csv\",index_col='Respondent')\n",
    "                df.drop(['bash'], axis=1,inplace = True)\n",
    "                userlanguages=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(input_path+\"frameworks_profile_user.csv\",index_col='Respondent')\n",
    "                userframeworks=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(input_path+\"platforms_profile_user.csv\",index_col='Respondent')\n",
    "                userplatforms=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(input_path+\"databases_profile_user.csv\",index_col='Respondent')\n",
    "                userdatabases=df.loc[user_id,:]\n",
    "\n",
    "                userdomain=np.asarray(userdomain.fillna(0))\n",
    "                userlanguages=np.asarray(userlanguages.fillna(0))\n",
    "                userframeworks=np.asarray(userframeworks.fillna(0))\n",
    "                userplatforms=np.asarray(userplatforms.fillna(0))\n",
    "                userdatabases=np.asarray(userdatabases.fillna(0))\n",
    "                #print(userdomain)\n",
    "            else:\n",
    "                print(\"error! user id not in Dataset\")\n",
    "            #If it doesn't,take user profile as input\n",
    "        else:\n",
    "\n",
    "            print(\"New user!Enter details..\")\n",
    "            name=input(\"Enter full name\")\n",
    "            skills=input(\"Enter skills(comma separated). These are programming languages, frameworks,platforms or databases you have experience with\").split(\",\")\n",
    "            domains=''\n",
    "            flag=1\n",
    "            while(1):\n",
    "                print(\"Enter domain(s) of interest separated by commas(Names are case sensitive). Should be one of the following:\")\n",
    "                for i in df.columns:\n",
    "                    print(i,end=\",\")\n",
    "                domains=input().split(\",\")\n",
    "                for domain in domains:\n",
    "                    if(domain not in df.columns):\n",
    "                        flag=0\n",
    "                        break\n",
    "                if(flag==1):\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Please enter valid domain\")\n",
    "            #domains=list(map(lambda x:x.lower(),domains))\n",
    "            skills=list(map(lambda x:x.lower(),skills))                \n",
    "\n",
    "            userdomain=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for domain in domains:\n",
    "                dictionary[domain]=1.0\n",
    "            userdomain=userdomain.append(dictionary,ignore_index=True)\n",
    "\n",
    "\n",
    "            df=pd.read_csv(input_path+\"languages_profile_user.csv\",index_col='Respondent')\n",
    "            userlanguages=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userlanguages=userlanguages.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(input_path+\"frameworks_profile_user.csv\",index_col='Respondent')\n",
    "            userframeworks=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userframeworks=userframeworks.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(input_path+\"platforms_profile_user.csv\",index_col='Respondent')\n",
    "            userplatforms=pd.DataFrame(columns=df.columns)                \n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userplatforms=userplatforms.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(input_path+\"databases_profile_user.csv\",index_col='Respondent')\n",
    "            userdatabases=pd.DataFrame(columns=df.columns)               \n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userdatabases=userdatabases.append(dictionary,ignore_index=True)\n",
    "            #print(userdomain)\n",
    "            userdomain.head()\n",
    "            userdomain=np.asarray(userdomain.iloc[0,:].fillna(0))\n",
    "            userlanguages=np.asarray(userlanguages.iloc[0,:].fillna(0))\n",
    "            userframeworks=np.asarray(userframeworks.iloc[0,:].fillna(0))\n",
    "            userplatforms=np.asarray(userplatforms.iloc[0,:].fillna(0))\n",
    "            userdatabases=np.asarray(userdatabases.iloc[0,:].fillna(0))\n",
    "                \n",
    "        jobdomain=pd.read_csv(input_path+\"domain_job_profile.csv\",index_col='uniq_id')\n",
    "        joblanguages=pd.read_csv(input_path+'languages_profile_job.csv',index_col='uniq_id')\n",
    "        jobframeworks=pd.read_csv(input_path+'frameworks_profile_job.csv',index_col='uniq_id')\n",
    "        jobplatforms=pd.read_csv(input_path+'platforms_profile_job.csv',index_col='uniq_id')\n",
    "        jobdatabases=pd.read_csv(input_path+'databases_profile_job.csv',index_col='uniq_id')\n",
    "        \n",
    "        #print(len(jobdomain.index),len(joblanguages.index))\n",
    "        for i,j in zip(jobdomain.index,joblanguages.index):\n",
    "            #print(i)\n",
    "            domain=jobdomain.iloc[i,:].fillna(0)\n",
    "            language=joblanguages.iloc[i,:].fillna(0)\n",
    "            framework=jobframeworks.iloc[i,:].fillna(0)\n",
    "            platform=jobplatforms.iloc[i,:].fillna(0)\n",
    "            database=jobdatabases.iloc[i,:].fillna(0)\n",
    "            #print('Uniq_id: ',joblanguages['uniq_id'])\n",
    "            job_id=str(j)\n",
    "            \n",
    "            domain=np.asarray(domain)\n",
    "            language=np.asarray(language)\n",
    "            framework=np.asarray(framework)\n",
    "            platform=np.asarray(platform)\n",
    "            database=np.asarray(database)\n",
    "            \n",
    "            #print(language)\n",
    "            #print(userlanguages)\n",
    "            \n",
    "            score=(alpha*cosine_similarity(domain,userdomain))+(beta*(cosine_similarity(language,userlanguages)+cosine_similarity(framework,userframeworks)+cosine_similarity(platform,userplatforms)+cosine_similarity(database,userdatabases)))\n",
    "            matches[job_id]=score\n",
    "            score=(alpha*cosine_similarity(domain,userdomain))+(beta*(cosine_similarity(language,userlanguages)+cosine_similarity(framework,userframeworks)+cosine_similarity(platform,userplatforms)+cosine_similarity(database,userdatabases)))\n",
    "            \n",
    "            #Initializing job profiles for later access\n",
    "            self.job_domain=domain\n",
    "            self.job_language=language\n",
    "            self.job_framework=framework\n",
    "            self.job_platform=platform\n",
    "            self.job_database=database\n",
    "            \n",
    "            self.user_domain=userdomain\n",
    "            self.user_language=userlanguages\n",
    "            self.user_framework=userframeworks\n",
    "            self.user_platform=userplatforms\n",
    "            self.user_database=userdatabases\n",
    "        matches=sorted(matches.items(),key=lambda x:x[1],reverse=True)\n",
    "        \n",
    "        recommendations=matches[:5]\n",
    "        print(\"The top 5 Recommendations for User\",user_id,\"based on content-based filtering are:\")\n",
    "        \n",
    "        # Recommendation dataframe\n",
    "        ls = ['Respondent']\n",
    "        for col in jobs.columns:\n",
    "            ls.append(col)\n",
    "        rows=pd.DataFrame(columns=ls)\n",
    "        row=pd.DataFrame(columns=ls)\n",
    "        count=0\n",
    "        for i in recommendations:\n",
    "            row.loc[count,'Respondent'] = user_id\n",
    "            for col in jobs.columns:\n",
    "                row[col] = jobs[jobs['uniq_id']==i[0]][col]\n",
    "                \n",
    "            #row=self.df2[self.df2['uniq_id']==i[0]]\n",
    "            #rows[count]=np.asarray(row.values.T.tolist()[0])\n",
    "            rows=rows.append(row.iloc[0])\n",
    "            row=pd.DataFrame(columns=ls)\n",
    "            count=count+1\n",
    "            #print(row)\n",
    "        #return rows\n",
    "        #return recommendations\n",
    "        for i in recommendations:\n",
    "            print('Job Unique Id:',i[0])\n",
    "        return rows,recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a52ce13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=job_postings(\"./dataset/dice_com-job_us_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdb4b09",
   "metadata": {},
   "source": [
    "## Generating recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab16a351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 Recommendations for User 4 based on content-based filtering are:\n",
      "Job Unique Id: 418ff92580b270ef4e7c14f0ddfc36b4\n",
      "Job Unique Id: 8aec88cba08d53da65ab99cf20f6f9d9\n",
      "Job Unique Id: 46baa1f69ac07779274bcd90b85d9a72\n",
      "Job Unique Id: 3941b2f206ae0f900c4fba4ac0b18719\n",
      "Job Unique Id: 45efa1f6bc65acc32bbbb953a1ed13b7\n",
      "Job Unique Id: e0ac9d926dda5e95162ef05adea7318c\n",
      "Job Unique Id: e7e326053c586bd94e59f1fd74de4a1b\n",
      "Job Unique Id: b0dadecf4c3c2beecb9c773ca11ecda4\n",
      "Job Unique Id: 28f5e0c1cc3314813e674f0c32b04d1b\n",
      "Job Unique Id: 95c9127e2770172f454f3b83981eaa88\n"
     ]
    }
   ],
   "source": [
    "# For user = 4 & parameter for alpha=0.0 & beta=1.0\n",
    "user_id = 4\n",
    "rows,recommendations = obj.match_profile(\"./dataset/\",user_id,alpha=0.0,beta=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b743b8",
   "metadata": {},
   "source": [
    "## Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0daf7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rows.to_csv(\"./dataset/recommendations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4aa33b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 Recommendations for User 4 based on content-based filtering are:\n",
      "Job Unique Id: b9520049ff3e799ec368ae0aa99ec5f5\n",
      "Job Unique Id: 755688570dda03850c9ea9974e241110\n",
      "Job Unique Id: 0d92b51b694ef046360f989fa92a15ac\n",
      "Job Unique Id: 4a737efc3dd5fe84a532e94b609ee484\n",
      "Job Unique Id: 4a3f8742fae151757eb290a774968371\n",
      "Job Unique Id: 4c8b7a93f5707a08b538f4e79d6a7f30\n",
      "Job Unique Id: fe9741051b3a8971f4a1156b07ece236\n",
      "Job Unique Id: 713931543d0ec81e0e09d498b7258164\n",
      "Job Unique Id: 12b6b02d3498a1d0432d9669a50087ef\n",
      "Job Unique Id: bd4eee9b197c066d9bff44452452c5b1\n"
     ]
    }
   ],
   "source": [
    "# For user = 5 & parameter for alpha=0.0 & beta=1.0\n",
    "user_id = 4\n",
    "rows,recommendations = obj.match_profile(\"./dataset/\",user_id,alpha=0.7,beta=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f178ca61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 Recommendations for User 7 based on content-based filtering are:\n",
      "Job Unique Id: 9c1dae8f8326ff44336cbc65c4145524\n",
      "Job Unique Id: f7fac0c163a247d4f85c04e3dc823a7e\n",
      "Job Unique Id: 3071e1d037c43c96e63d87b7f798904c\n",
      "Job Unique Id: 3142c2dd6924df52d463d81ef93fb6e4\n",
      "Job Unique Id: 0445fcb37ab17f686c025da15a98de52\n",
      "Job Unique Id: 7fd3441f67f66c3406e538ab337f1a66\n",
      "Job Unique Id: 0bed3d9c4ed99d5cc1a2649f59bc2896\n",
      "Job Unique Id: 418ff92580b270ef4e7c14f0ddfc36b4\n",
      "Job Unique Id: 46baa1f69ac07779274bcd90b85d9a72\n",
      "Job Unique Id: e0ac9d926dda5e95162ef05adea7318c\n"
     ]
    }
   ],
   "source": [
    "# For user = 5 & parameter for alpha=0.0 & beta=1.0\n",
    "user_id = 7\n",
    "rows,recommendations = obj.match_profile(\"./dataset/\",user_id,alpha=0.001,beta=0.999)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
