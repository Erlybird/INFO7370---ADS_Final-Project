{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d404a281",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9fbe25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56108bd",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2963701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies = pd.read_csv('./dataset/imbd/movies_metadata.csv')\n",
    "jobs = pd.read_csv('./dataset/dice_com-job_us_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f525d3ce",
   "metadata": {},
   "source": [
    "# Job Recommendations based on Job Descriptions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d27fa1",
   "metadata": {},
   "source": [
    "## TfidfVectorizer - Convert to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1b05d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22000, 117417)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "jobs['jobdescription'] = jobs['jobdescription'].fillna('')\n",
    "\n",
    "#Construct the required TF-IDF matrix by applying the fit_transform method on the overview feature\n",
    "overview_matrix = tfidf.fit_transform(jobs['jobdescription'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "overview_matrix.shape\n",
    "\n",
    "#Every jobs description has 117417 number of features (words )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb0f8f8",
   "metadata": {},
   "source": [
    "## Building the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407813c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = linear_kernel(overview_matrix,overview_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91376064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.05712901, 0.08229116, ..., 0.16367784, 0.12781094,\n",
       "        0.03852916],\n",
       "       [0.05712901, 1.        , 0.04510606, ..., 0.08193473, 0.06210229,\n",
       "        0.02303946],\n",
       "       [0.08229116, 0.04510606, 1.        , ..., 0.13467453, 0.07733971,\n",
       "        0.01152106],\n",
       "       ...,\n",
       "       [0.16367784, 0.08193473, 0.13467453, ..., 1.        , 0.11182536,\n",
       "        0.02333776],\n",
       "       [0.12781094, 0.06210229, 0.07733971, ..., 0.11182536, 1.        ,\n",
       "        0.02400144],\n",
       "       [0.03852916, 0.02303946, 0.01152106, ..., 0.02333776, 0.02400144,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1045e3b7",
   "metadata": {},
   "source": [
    "## Jobs index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ad57a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniq_id\n",
       "418ff92580b270ef4e7c14f0ddfc36b4        0\n",
       "8aec88cba08d53da65ab99cf20f6f9d9        1\n",
       "46baa1f69ac07779274bcd90b85d9a72        2\n",
       "3941b2f206ae0f900c4fba4ac0b18719        3\n",
       "45efa1f6bc65acc32bbbb953a1ed13b7        4\n",
       "                                    ...  \n",
       "86e27ce6b7e631e55d69d142c7d43df2    21995\n",
       "4287c7ee3317ccf1edd76e238cf8e584    21996\n",
       "d7512f0181d69f83f96db38cd77a4d08    21997\n",
       "ec375268b494b3bcbed1635d64226112    21998\n",
       "9a4e8c27f74af4c0d2f6efbd420a8a91    21999\n",
       "Length: 22000, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = pd.Series(jobs.index,index = jobs['uniq_id'])\n",
    "mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e132583",
   "metadata": {},
   "source": [
    "## Building Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812fe42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_jobs_based_on_description(job_input):\n",
    "    \n",
    "    job_index = mapping[job_input]\n",
    "    #get similarity values with other movies\n",
    "    \n",
    "    #similarity_score is the list of index and similarity matrix\n",
    "    similarity_score = list(enumerate(similarity_matrix[job_index]))\n",
    "    #print(similarity_matrix[job_index])\n",
    "    \n",
    "    #sort in descending order the similarity score of movie inputted with all the other movies\n",
    "    similarity_score = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the scores of the 10 most similar movies. Ignore the first movie.\n",
    "    similarity_score = similarity_score[1:10]\n",
    "    \n",
    "    #return movie names using the mapping series\n",
    "    job_indices = [i[0] for i in similarity_score]\n",
    "    \n",
    "    return (jobs['jobtitle'].iloc[job_indices] + ' @ ' + jobs['company'].iloc[job_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54a192c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19680    Websphere Commerce Developer (Locals to MI) @ ...\n",
       "8030     WebSphere-MQ Administrator @ Randstad Technolo...\n",
       "18191    Java multiple positions $75K to $130K + bonus ...\n",
       "6164              SDET @ Paramount Software Solutions, Inc\n",
       "12420             SDET @ Paramount Software Solutions, Inc\n",
       "6297     WebSphere Message Queue (WMQ) admin / WebSpher...\n",
       "16990       MDMS (Meter Data Management System) @ Startekk\n",
       "9601     Websphere Commerce Applications Architect @ Th...\n",
       "10633                   WebSphere Admin @ SV Professionals\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_jobs_based_on_description('418ff92580b270ef4e7c14f0ddfc36b4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc56bd",
   "metadata": {},
   "source": [
    "## Using the combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cf0c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(arr1,arr2):\n",
    "    ans=1- spatial.distance.cosine(arr1,arr2)\n",
    "    if(np.isnan(ans)):\n",
    "        return 0\n",
    "    else:\n",
    "        return ans\n",
    "class job_postings:    \n",
    "    def __init__(self,link):\n",
    "        self.df2=pd.read_csv(link)\n",
    "        self.training_range=int(len(self.df2.loc[:,'uniq_id']))\n",
    "    def match_profile(self,input_path,user_id,flag=0):\n",
    "        #Match a given user_id with all jobs in the database\n",
    "        \n",
    "        #Check if user id exists\n",
    "        df=pd.read_csv(input_path+\"domain_user_profile.csv\",index_col='Respondent')\n",
    "        #print(df.columns)\n",
    "        matches=dict()\n",
    "        if(flag==0):\n",
    "            if(user_id in df.index):\n",
    "                userdomain=df.loc[user_id,:]\n",
    "                #print(userdomain)\n",
    "                #If it does, retrieve the user profile from input_path\n",
    "                df=pd.read_csv(input_path+\"languages_profile_user.csv\",index_col='Respondent')\n",
    "                df.drop(['bash'], axis=1,inplace = True)\n",
    "                userlanguages=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(input_path+\"frameworks_profile_user.csv\",index_col='Respondent')\n",
    "                userframeworks=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(input_path+\"platforms_profile_user.csv\",index_col='Respondent')\n",
    "                userplatforms=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(input_path+\"databases_profile_user.csv\",index_col='Respondent')\n",
    "                userdatabases=df.loc[user_id,:]\n",
    "\n",
    "                userdomain=np.asarray(userdomain.fillna(0))\n",
    "                userlanguages=np.asarray(userlanguages.fillna(0))\n",
    "                userframeworks=np.asarray(userframeworks.fillna(0))\n",
    "                userplatforms=np.asarray(userplatforms.fillna(0))\n",
    "                userdatabases=np.asarray(userdatabases.fillna(0))\n",
    "                #print(userdomain)\n",
    "            else:\n",
    "                print(\"error! user id not in Dataset\")\n",
    "            #If it doesn't,take user profile as input\n",
    "        else:\n",
    "\n",
    "            print(\"New user!Enter details..\")\n",
    "            name=input(\"Enter full name\")\n",
    "            skills=input(\"Enter skills(comma separated). These are programming languages, frameworks,platforms or databases you have experience with\").split(\",\")\n",
    "            domains=''\n",
    "            flag=1\n",
    "            while(1):\n",
    "                print(\"Enter domain(s) of interest separated by commas(Names are case sensitive). Should be one of the following:\")\n",
    "                for i in df.columns:\n",
    "                    print(i,end=\",\")\n",
    "                domains=input().split(\",\")\n",
    "                for domain in domains:\n",
    "                    if(domain not in df.columns):\n",
    "                        flag=0\n",
    "                        break\n",
    "                if(flag==1):\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Please enter valid domain\")\n",
    "            #domains=list(map(lambda x:x.lower(),domains))\n",
    "            skills=list(map(lambda x:x.lower(),skills))                \n",
    "\n",
    "            userdomain=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for domain in domains:\n",
    "                dictionary[domain]=1.0\n",
    "            userdomain=userdomain.append(dictionary,ignore_index=True)\n",
    "\n",
    "\n",
    "            df=pd.read_csv(input_path+\"languages_profile_user.csv\",index_col='Respondent')\n",
    "            userlanguages=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userlanguages=userlanguages.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(input_path+\"frameworks_profile_user.csv\",index_col='Respondent')\n",
    "            userframeworks=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userframeworks=userframeworks.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(input_path+\"platforms_profile_user.csv\",index_col='Respondent')\n",
    "            userplatforms=pd.DataFrame(columns=df.columns)                \n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userplatforms=userplatforms.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(input_path+\"databases_profile_user.csv\",index_col='Respondent')\n",
    "            userdatabases=pd.DataFrame(columns=df.columns)               \n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userdatabases=userdatabases.append(dictionary,ignore_index=True)\n",
    "            #print(userdomain)\n",
    "            userdomain.head()\n",
    "            userdomain=np.asarray(userdomain.iloc[0,:].fillna(0))\n",
    "            userlanguages=np.asarray(userlanguages.iloc[0,:].fillna(0))\n",
    "            userframeworks=np.asarray(userframeworks.iloc[0,:].fillna(0))\n",
    "            userplatforms=np.asarray(userplatforms.iloc[0,:].fillna(0))\n",
    "            userdatabases=np.asarray(userdatabases.iloc[0,:].fillna(0))\n",
    "                \n",
    "        jobdomain=pd.read_csv(input_path+\"domain_job_profile.csv\",index_col='uniq_id')\n",
    "        joblanguages=pd.read_csv(input_path+'languages_profile_job.csv',index_col='uniq_id')\n",
    "        jobframeworks=pd.read_csv(input_path+'frameworks_profile_job.csv',index_col='uniq_id')\n",
    "        jobplatforms=pd.read_csv(input_path+'platforms_profile_job.csv',index_col='uniq_id')\n",
    "        jobdatabases=pd.read_csv(input_path+'databases_profile_job.csv',index_col='uniq_id')\n",
    "        \n",
    "        #print(len(jobdomain.index),len(joblanguages.index))\n",
    "        for i,j in zip(jobdomain.index,joblanguages.index):\n",
    "            #print(i)\n",
    "            domain=jobdomain.iloc[i,:].fillna(0)\n",
    "            language=joblanguages.iloc[i,:].fillna(0)\n",
    "            framework=jobframeworks.iloc[i,:].fillna(0)\n",
    "            platform=jobplatforms.iloc[i,:].fillna(0)\n",
    "            database=jobdatabases.iloc[i,:].fillna(0)\n",
    "            #print('Uniq_id: ',joblanguages['uniq_id'])\n",
    "            job_id=str(j)\n",
    "            \n",
    "            domain=np.asarray(domain)\n",
    "            language=np.asarray(language)\n",
    "            framework=np.asarray(framework)\n",
    "            platform=np.asarray(platform)\n",
    "            database=np.asarray(database)\n",
    "            \n",
    "            #print(language)\n",
    "            #print(userlanguages)\n",
    "            \n",
    "            score=(0.7*cosine_similarity(domain,userdomain))+(0.3*(cosine_similarity(language,userlanguages)+cosine_similarity(framework,userframeworks)+cosine_similarity(platform,userplatforms)+cosine_similarity(database,userdatabases)))\n",
    "            matches[job_id]=score\n",
    "            score=(0.7*cosine_similarity(domain,userdomain))+(0.3*(cosine_similarity(language,userlanguages)+cosine_similarity(framework,userframeworks)+cosine_similarity(platform,userplatforms)+cosine_similarity(database,userdatabases)))\n",
    "            \n",
    "            #Initializing job profiles for later access\n",
    "            self.job_domain=domain\n",
    "            self.job_language=language\n",
    "            self.job_framework=framework\n",
    "            self.job_platform=platform\n",
    "            self.job_database=database\n",
    "            \n",
    "            self.user_domain=userdomain\n",
    "            self.user_language=userlanguages\n",
    "            self.user_framework=userframeworks\n",
    "            self.user_platform=userplatforms\n",
    "            self.user_database=userdatabases\n",
    "        matches=sorted(matches.items(),key=lambda x:x[1],reverse=True)\n",
    "        \n",
    "        recommendations=matches[:5]\n",
    "        print(\"The top 5 Recommendations for User \",user_id,\"based on content-based filtering are:\")\n",
    "        for i in recommendations:\n",
    "            print('Job Unique Id:',i[0])\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e1251fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=job_postings(\"./dataset/dice_com-job_us_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5ef157",
   "metadata": {},
   "source": [
    "## Start  recommending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b52ce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18573\\anaconda3\\envs\\ads\\lib\\site-packages\\scipy\\spatial\\distance.py:630: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 Recommendations for User  7  based on content-based filtering are:\n",
      "Job Unique Id: 9c1dae8f8326ff44336cbc65c4145524\n",
      "Job Unique Id: f7fac0c163a247d4f85c04e3dc823a7e\n",
      "Job Unique Id: 3071e1d037c43c96e63d87b7f798904c\n",
      "Job Unique Id: 3142c2dd6924df52d463d81ef93fb6e4\n",
      "Job Unique Id: 0445fcb37ab17f686c025da15a98de52\n"
     ]
    }
   ],
   "source": [
    "user_id = 7\n",
    "rows=obj.match_profile(\"./dataset/\",user_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
